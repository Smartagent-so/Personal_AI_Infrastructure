#!/usr/bin/env bun
/**
 * PAIVoice - Personal AI Voice notification server using ElevenLabs TTS
 */

import { serve } from "bun";
import { spawn } from "child_process";
import { homedir } from "os";
import { join } from "path";
import { existsSync } from "fs";

// Load .env from user home directory
const envPath = join(homedir(), '.env');
if (existsSync(envPath)) {
  const envContent = await Bun.file(envPath).text();
  envContent.split('\n').forEach(line => {
    const [key, value] = line.split('=');
    if (key && value && !key.startsWith('#')) {
      process.env[key.trim()] = value.trim();
    }
  });
}

const PORT = parseInt(process.env.PORT || "***REMOVED***");
const ELEVENLABS_API_KEY = process.env.ELEVENLABS_API_KEY;

if (!ELEVENLABS_API_KEY) {
  console.error('‚ö†Ô∏è  ELEVENLABS_API_KEY not found in ~/.env');
  console.error('Add: ELEVENLABS_API_KEY=your_key_here');
}

// Voice IDs for language-based selection
const VOICES = {
  jarvis: "pxQ5J1NTCCuhK7jrRa1d",  // English - PAI System Voice
  ottie: "***REMOVED***",   // German - Ostfriesisch
};

// Default voice ID (Jarvis for English)
const DEFAULT_VOICE_ID = process.env.ELEVENLABS_VOICE_ID || VOICES.jarvis;

// Default model - eleven_flash_v2_5 for ultra-low latency
// See: https://elevenlabs.io/docs/models#models-overview
// Options: eleven_flash_v2_5 (fastest), eleven_turbo_v2_5 (balanced), ***REMOVED*** (quality)
const DEFAULT_MODEL = process.env.ELEVENLABS_MODEL || "eleven_flash_v2_5";

// Streaming configuration
const STREAMING_ENABLED = process.env.VOICE_STREAMING !== "false";
const STREAM_BUFFER_MS = 300; // Start playback after this many ms of audio buffered

// Simple language detection based on German-specific patterns
function detectLanguage(text: string): "de" | "en" {
  const germanPatterns = [
    // Pronouns
    /\b(ich|du|er|sie|es|wir|ihr|mich|dich|sich|mir|dir|ihm|uns|euch)\b/i,
    // Conjunctions
    /\b(und|oder|aber|wenn|dass|weil|denn|ob|als|damit|obwohl)\b/i,
    // Common verbs (sein, haben, werden, k√∂nnen, m√ºssen, etc.)
    /\b(bin|bist|ist|sind|war|waren|habe|hast|hat|haben|hatte|werde|wird|werden|kann|kannst|k√∂nnen|muss|m√ºssen|soll|sollte|will|wollen|mag|m√∂chte|darf)\b/i,
    // Articles & pronouns
    /\b(der|die|das|den|dem|des|ein|eine|einer|einem|einen|kein|keine|dieser|diese|dieses|welche|welcher)\b/i,
    // Adverbs & particles
    /\b(nicht|auch|noch|schon|nur|sehr|mehr|viel|jetzt|hier|dort|heute|immer|wieder|gerade|eigentlich)\b/i,
    // Umlauts & √ü (strong indicator)
    /[√§√∂√º√ü]/i,
    // Common German words & greetings
    /\b(hallo|moin|tsch√ºss|danke|bitte|ja|nein|gut|schlecht|spreche|sprechen|spricht|heisse|hei√üt|verstehe|brauche|finde|glaube|denke|weiss|wei√ü|neue|neuen|neuer)\b/i,
  ];

  let germanScore = 0;
  for (const pattern of germanPatterns) {
    if (pattern.test(text)) {
      germanScore++;
    }
  }

  // If 2+ German patterns match, consider it German
  return germanScore >= 2 ? "de" : "en";
}

// Select voice based on detected language
function selectVoiceByLanguage(text: string): string {
  const lang = detectLanguage(text);
  const voice = lang === "de" ? VOICES.ottie : VOICES.jarvis;
  console.log(`üåê Language detected: ${lang.toUpperCase()} ‚Üí Voice: ${lang === "de" ? "Ottie" : "Jarvis"}`);
  return voice;
}

// Sanitize input for shell commands (allows German umlauts)
function sanitizeForShell(input: string): string {
  return input.replace(/[^a-zA-Z0-9√§√∂√º√Ñ√ñ√ú√ü\s.,!?\-']/g, '').trim().substring(0, 500);
}

// Validate and sanitize user input
function validateInput(input: any): { valid: boolean; error?: string } {
  if (!input || typeof input !== 'string') {
    return { valid: false, error: 'Invalid input type' };
  }

  if (input.length > 500) {
    return { valid: false, error: 'Message too long (max 500 characters)' };
  }

  const dangerousPatterns = [
    /[;&|><`\$\(\)\{\}\[\]\\]/,
    /\.\.\//,
    /<script/i,
  ];

  for (const pattern of dangerousPatterns) {
    if (pattern.test(input)) {
      return { valid: false, error: 'Invalid characters in input' };
    }
  }

  return { valid: true };
}

// Generate speech using ElevenLabs API (non-streaming fallback)
async function generateSpeech(text: string, voiceId: string): Promise<ArrayBuffer> {
  if (!ELEVENLABS_API_KEY) {
    throw new Error('ElevenLabs API key not configured');
  }

  const url = `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`;

  const response = await fetch(url, {
    method: 'POST',
    headers: {
      'Accept': 'audio/mpeg',
      'Content-Type': 'application/json',
      'xi-api-key': ELEVENLABS_API_KEY,
    },
    body: JSON.stringify({
      text: text,
      model_id: DEFAULT_MODEL,
      voice_settings: {
        stability: 0.5,
        similarity_boost: 0.5,
      },
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    if (errorText.includes('model') || response.status === 422) {
      throw new Error(`ElevenLabs API error: Invalid model "${DEFAULT_MODEL}". Update ELEVENLABS_MODEL in ~/.env. See https://elevenlabs.io/docs/models`);
    }
    throw new Error(`ElevenLabs API error: ${response.status} - ${errorText}`);
  }

  return await response.arrayBuffer();
}

// Generate speech with streaming for lower latency
async function generateSpeechStreaming(text: string, voiceId: string): Promise<void> {
  if (!ELEVENLABS_API_KEY) {
    throw new Error('ElevenLabs API key not configured');
  }

  const url = `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}/stream`;
  const tempFile = `/tmp/voice-stream-${Date.now()}.mp3`;

  console.log(`‚ö° Streaming mode: ${url}`);
  const startTime = Date.now();

  const response = await fetch(url, {
    method: 'POST',
    headers: {
      'Accept': 'audio/mpeg',
      'Content-Type': 'application/json',
      'xi-api-key': ELEVENLABS_API_KEY,
    },
    body: JSON.stringify({
      text: text,
      model_id: DEFAULT_MODEL,
      voice_settings: {
        stability: 0.5,
        similarity_boost: 0.75,
      },
      optimize_streaming_latency: 4, // Maximum optimization (0-4)
    }),
  });

  if (!response.ok) {
    const errorText = await response.text();
    throw new Error(`ElevenLabs Streaming API error: ${response.status} - ${errorText}`);
  }

  if (!response.body) {
    throw new Error('No response body for streaming');
  }

  // Stream chunks to file and start playback early
  const reader = response.body.getReader();
  const file = Bun.file(tempFile);
  const writer = file.writer();

  let totalBytes = 0;
  let playbackStarted = false;
  let playbackProcess: ReturnType<typeof spawn> | null = null;
  const firstChunkTime = Date.now();

  try {
    while (true) {
      const { done, value } = await reader.read();

      if (done) break;

      if (value) {
        writer.write(value);
        totalBytes += value.length;

        // Start playback after receiving enough data (~10KB is about 0.5s of audio)
        // This allows audio to start playing while still downloading
        if (!playbackStarted && totalBytes > 10000) {
          await writer.flush();

          const latencyMs = Date.now() - startTime;
          console.log(`üéµ Starting playback after ${latencyMs}ms (${totalBytes} bytes buffered)`);

          playbackProcess = spawn('/usr/bin/afplay', [tempFile]);
          playbackStarted = true;
        }
      }
    }

    await writer.end();

    const totalTime = Date.now() - startTime;
    console.log(`‚úÖ Stream complete: ${totalBytes} bytes in ${totalTime}ms`);

    // If playback hasn't started yet (very short text), start it now
    if (!playbackStarted) {
      const latencyMs = Date.now() - startTime;
      console.log(`üéµ Starting playback after ${latencyMs}ms (short text, ${totalBytes} bytes)`);
      playbackProcess = spawn('/usr/bin/afplay', [tempFile]);
    }

    // Wait for playback to complete
    if (playbackProcess) {
      await new Promise<void>((resolve, reject) => {
        playbackProcess!.on('exit', (code) => {
          spawn('/bin/rm', ['-f', tempFile]);
          if (code === 0) resolve();
          else reject(new Error(`afplay exited with code ${code}`));
        });
        playbackProcess!.on('error', reject);
      });
    }

  } catch (error) {
    // Cleanup on error
    if (playbackProcess) {
      playbackProcess.kill();
    }
    spawn('/bin/rm', ['-f', tempFile]);
    throw error;
  }
}

// Play audio using afplay (macOS)
async function playAudio(audioBuffer: ArrayBuffer): Promise<void> {
  const tempFile = `/tmp/voice-${Date.now()}.mp3`;

  // Write audio to temp file
  await Bun.write(tempFile, audioBuffer);

  return new Promise((resolve, reject) => {
    const proc = spawn('/usr/bin/afplay', [tempFile]);

    proc.on('error', (error) => {
      console.error('Error playing audio:', error);
      reject(error);
    });

    proc.on('exit', (code) => {
      // Clean up temp file
      spawn('/bin/rm', [tempFile]);

      if (code === 0) {
        resolve();
      } else {
        reject(new Error(`afplay exited with code ${code}`));
      }
    });
  });
}

// Spawn a process safely
function spawnSafe(command: string, args: string[]): Promise<void> {
  return new Promise((resolve, reject) => {
    const proc = spawn(command, args);

    proc.on('error', (error) => {
      console.error(`Error spawning ${command}:`, error);
      reject(error);
    });

    proc.on('exit', (code) => {
      if (code === 0) {
        resolve();
      } else {
        reject(new Error(`${command} exited with code ${code}`));
      }
    });
  });
}

// Send macOS notification with voice
async function sendNotification(
  title: string,
  message: string,
  voiceEnabled = true,
  voiceId: string | null = null,
  useStreaming: boolean = STREAMING_ENABLED
) {
  // Validate inputs
  const titleValidation = validateInput(title);
  const messageValidation = validateInput(message);

  if (!titleValidation.valid) {
    throw new Error(`Invalid title: ${titleValidation.error}`);
  }

  if (!messageValidation.valid) {
    throw new Error(`Invalid message: ${messageValidation.error}`);
  }

  // Sanitize inputs
  const safeTitle = sanitizeForShell(title);
  const safeMessage = sanitizeForShell(message);

  // Generate and play voice using ElevenLabs
  if (voiceEnabled && ELEVENLABS_API_KEY) {
    try {
      // Auto-detect language if no specific voice is requested
      const voice = voiceId || selectVoiceByLanguage(message);
      console.log(`üéôÔ∏è  Generating speech with ElevenLabs (voice: ${voice}, streaming: ${useStreaming})`);

      if (useStreaming) {
        // Use streaming for lower latency
        await generateSpeechStreaming(safeMessage, voice);
      } else {
        // Fallback to non-streaming
        const audioBuffer = await generateSpeech(safeMessage, voice);
        await playAudio(audioBuffer);
      }
    } catch (error) {
      console.error("Failed to generate/play speech:", error);

      // If streaming fails, try non-streaming as fallback
      if (useStreaming) {
        console.log("‚ö†Ô∏è  Streaming failed, trying non-streaming fallback...");
        try {
          const voice = voiceId || selectVoiceByLanguage(message);
          const audioBuffer = await generateSpeech(safeMessage, voice);
          await playAudio(audioBuffer);
        } catch (fallbackError) {
          console.error("Fallback also failed:", fallbackError);
        }
      }
    }
  }

  // Display macOS notification
  try {
    const script = `display notification "${safeMessage}" with title "${safeTitle}" sound name ""`;
    await spawnSafe('/usr/bin/osascript', ['-e', script]);
  } catch (error) {
    console.error("Notification display error:", error);
  }
}

// Rate limiting
const requestCounts = new Map<string, { count: number; resetTime: number }>();
const RATE_LIMIT = 10;
const RATE_WINDOW = 60000;

function checkRateLimit(ip: string): boolean {
  const now = Date.now();
  const record = requestCounts.get(ip);

  if (!record || now > record.resetTime) {
    requestCounts.set(ip, { count: 1, resetTime: now + RATE_WINDOW });
    return true;
  }

  if (record.count >= RATE_LIMIT) {
    return false;
  }

  record.count++;
  return true;
}

// Start HTTP server
const server = serve({
  port: PORT,
  async fetch(req) {
    const url = new URL(req.url);

    const clientIp = req.headers.get('x-forwarded-for') || 'localhost';

    const corsHeaders = {
      "Access-Control-Allow-Origin": "http://localhost",
      "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
      "Access-Control-Allow-Headers": "Content-Type"
    };

    if (req.method === "OPTIONS") {
      return new Response(null, { headers: corsHeaders, status: 204 });
    }

    if (!checkRateLimit(clientIp)) {
      return new Response(
        JSON.stringify({ status: "error", message: "Rate limit exceeded" }),
        {
          headers: { ...corsHeaders, "Content-Type": "application/json" },
          status: 429
        }
      );
    }

    if (url.pathname === "/notify" && req.method === "POST") {
      try {
        const data = await req.json();
        const title = data.title || "PAI Notification";
        const message = data.message || "Task completed";
        const voiceEnabled = data.voice_enabled !== false;
        const voiceId = data.voice_id || data.voice_name || null; // Support both voice_id and voice_name
        const useStreaming = data.streaming !== false; // Default to streaming

        if (voiceId && typeof voiceId !== 'string') {
          throw new Error('Invalid voice_id');
        }

        console.log(`üì® Notification: "${title}" - "${message}" (voice: ${voiceEnabled}, streaming: ${useStreaming})`);

        await sendNotification(title, message, voiceEnabled, voiceId, useStreaming);

        return new Response(
          JSON.stringify({ status: "success", message: "Notification sent" }),
          {
            headers: { ...corsHeaders, "Content-Type": "application/json" },
            status: 200
          }
        );
      } catch (error: any) {
        console.error("Notification error:", error);
        return new Response(
          JSON.stringify({ status: "error", message: error.message || "Internal server error" }),
          {
            headers: { ...corsHeaders, "Content-Type": "application/json" },
            status: error.message?.includes('Invalid') ? 400 : 500
          }
        );
      }
    }

    if (url.pathname === "/pai" && req.method === "POST") {
      try {
        const data = await req.json();
        const title = data.title || "PAI Assistant";
        const message = data.message || "Task completed";

        console.log(`ü§ñ PAI notification: "${title}" - "${message}"`);

        await sendNotification(title, message, true, null);

        return new Response(
          JSON.stringify({ status: "success", message: "PAI notification sent" }),
          {
            headers: { ...corsHeaders, "Content-Type": "application/json" },
            status: 200
          }
        );
      } catch (error: any) {
        console.error("PAI notification error:", error);
        return new Response(
          JSON.stringify({ status: "error", message: error.message || "Internal server error" }),
          {
            headers: { ...corsHeaders, "Content-Type": "application/json" },
            status: error.message?.includes('Invalid') ? 400 : 500
          }
        );
      }
    }

    if (url.pathname === "/health") {
      return new Response(
        JSON.stringify({
          status: "healthy",
          port: PORT,
          voice_system: "ElevenLabs",
          model: DEFAULT_MODEL,
          streaming: STREAMING_ENABLED,
          optimize_streaming_latency: 4,
          voices: {
            english: { name: "Jarvis", id: VOICES.jarvis },
            german: { name: "Ottie", id: VOICES.ottie }
          },
          language_detection: "auto",
          api_key_configured: !!ELEVENLABS_API_KEY
        }),
        {
          headers: { ...corsHeaders, "Content-Type": "application/json" },
          status: 200
        }
      );
    }

    return new Response("PAIVoice Server - POST to /notify or /pai", {
      headers: corsHeaders,
      status: 200
    });
  },
});

console.log(`üöÄ PAIVoice Server running on port ${PORT}`);
console.log(`üéôÔ∏è  ElevenLabs TTS (model: ${DEFAULT_MODEL})`);
console.log(`‚ö° Streaming: ${STREAMING_ENABLED ? '‚úÖ ENABLED (low latency)' : '‚ùå Disabled'}`);
console.log(`üá¨üáß English ‚Üí Jarvis (${VOICES.jarvis})`);
console.log(`üá©üá™ German ‚Üí Ottie (${VOICES.ottie})`);
console.log(`üåê Language detection: AUTO`);
console.log(`üì° POST to http://localhost:${PORT}/notify`);
console.log(`üîí Security: CORS restricted to localhost, rate limiting enabled`);
console.log(`üîë API Key: ${ELEVENLABS_API_KEY ? '‚úÖ Configured' : '‚ùå Missing'}`);
